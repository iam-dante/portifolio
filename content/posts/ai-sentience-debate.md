---
title: "AI, LLMs, and the Sentience Debate: A Roommate Conversation"
date: "2026-02-26"
summary: "Femi was my roommate, and most of our daily talks on how AI is accelerating so fast every single day. Here's the argument we are always fighting about."
readingTime: 6
tags: ["Predictions"]
---

Femi was my roommate, and most of our daily talks on how AI is accelerating so fast every single day. I keep an eye on the AI community and what is going on daily new models, techniques and all that. But Femi thinks that AI meaning Large Language Models are sentient (able to perceive or feel things), due to the shock of how good these chatbot are.

So what is the argument here that we are always fighting?

---

<h2 class="text-2xl font-bold text-red-600 dark:text-red-400 mt-6 mb-3 pb-2 font-libre">The Debate</h2>

**Me:** These are just Autoregressive generative statistic models they don't understand anything they are fooling you.

**Femi:** They know too much in a wide range, when I talk to it feels magical.

**Me:** Yes it does because they have been trained on a large amount of text data.

**Femi:** So they know everything ?

**Me:** No. (a lot have been striped off and they are acting in a good behavior)

**Femi:** Why so ?

Then we start talk all the process of how they are being made the benefit and limitation of them.

---

<h2 class="text-2xl font-bold text-red-600 dark:text-red-400 mt-6 mb-3 pb-2 font-libre">AGI, ASI, and Everything in Between</h2>

The AGI/ ASI/ and everything in between that are talking about is so far away that to be even discussed now. We will know AGI when we achieve for now its just tool that are impressive.

To generalize everything that a human can do will require googlo byte in parameter size of models to do this well or to even come close. That is the G on the AGI, to generalize everything is bit of challenge, narrow AI on a specific tasks have show too much to be better than humans.

I don't believe in AGI or anything in between, I believe in narrow AGI for specific tasks such as chess, driving cars, coding and vacuum cleaners lol.

---

<h2 class="text-2xl font-bold text-red-600 dark:text-red-400 mt-6 mb-3 pb-2 font-libre">OpenClaw and the AGI Question</h2>

[OpenClaw](https://openclaw.ai) is a self-hosted gateway that connects your chat apps (WhatsApp, Telegram, Discord, iMessage, and more) to AI coding agents. You run it on your own machine, and it becomes the bridge between your messaging apps and an always-on AI assistant. It is agent native, built for coding agents with tool use, sessions, memory, and multi agent routing. One Gateway, multiple channels, your data stays on your hardware.

Femi accepts that this is close to something like AGI. The way it reasons, acts, and uses tools across sessions can feel like a step toward general intelligence. I keep telling him that OpenClaw is just a tool. In the conversation who cares about AGI?

**Femi:** If I have to convince you, who is in the field, about possibilities hoping some day you will catch on to the vision and probably join me in the March, while you find every reason it won't work, I must simply be wasting my time trying to convince you.

The link to AGI presence or not: impressive orchestration does not mean AGI is present. OpenClaw is a well built gateway that routes your messages to LLMs and runs agents on top of them. The magic is in the plumbing, sessions, routing, tool use, not in some new form of consciousness. It is narrow AI doing a specific job very well: connecting you to AI assistants across platforms. That is useful. It is not sentience, and it is not general intelligence.

---

<h2 class="text-2xl font-bold text-red-600 dark:text-red-400 mt-6 mb-3 pb-2 font-libre">The Human Brain</h2>

Jokes aside just imagine how much information that a human brain process in a millisecond. Vision, Sound, Touch, Emotions, Memory, and the most important the next action in a given environment.
